# LLM Configuration - Works with any OpenAI-compatible API
# 
# Option 1: Local Ollama (recommended for privacy and no API costs)
# Uncomment these lines and comment out the remote option:
# LLM_URL="http://ollama.default.svc.cluster.local:11434/v1"
# LLM_API_KEY="ollama"
# LLM_MODEL="qwen2.5:0.5b"  # or "llama3.2:3b", "mistral:7b", etc.

# Option 2: Remote LLM service (OpenAI, Azure, etc.)
# LLM_URL=https://api.openai.com/v1
# LLM_API_KEY=sk-your-key-here
# LLM_MODEL=gpt-4o